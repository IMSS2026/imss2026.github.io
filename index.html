<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>IMSS Lecture 2026</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<span class="logo"><img src="images/imss.png" alt="IMSS logo." /></span>
						<h1>IMSS Annual Lecture</h1>
						<h3>Institute of Mathematical & Statistical Sciences<h3>University College London</h3>


						<h3>Date: <b>27 April, 2026</b></h3>
				
						<h3>
						Location:
						<a href="https://maps.app.goo.gl/BmWw2cVmqgJFZvaS8"
							target="_blank"
							rel="noopener noreferrer">
							Gustave Tuck Lecture Theatre
						</a>
						</h3>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#about" class="active">About</a></li>
							<li><a href="registration">Registration and Posters</a></li>
							<li><a href="#schedule">Schedule</a></li>
							<li><a href="#speakers">Speakers</a></li>
							<li><a href="#organisers">Organisers</a></li>
							<li><a href="#location">Location</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="about" class="main">
							<div class="ucl-logo-wrapper">
								<img src="images/ucl200.png" alt="UCL 200 logo" class="ucl-logo">
							</div>
								<h4>
								This year‚Äôs annual lecture of the Institute for Mathematical and Statistical Sciences (IMSS) coincides with 
								<a href="https://www.ucl.ac.uk/about/ucls-bicentenary" target="_blank" rel="noopener noreferrer">UCL's 200th Bicentennary</a> 
								and will focus on the theme of ''Computational Statistics and Machine Learning''. 
								The UCL department of Statistical Science is delighted to welcome members of the community for an afternoon and evening of discussions on this topic, centered around a keynote talk by 
								<a href="https://lmackey.github.io/"
								rel="noopener noreferrer"
								style="font-weight: bold;">
								Dr. Lester Mackey 
								</a> 
								(Microsoft Research New England and Stanford University) as our keynote speaker. 
								The event will also feature invited talks covering topics in statistical machine learning, and will be followed by 
								<a href="https://fsml-ucl.github.io/CSMLworkshop2026/">a two-day workshop</a> 
								expanding on recent advanced in computational statistics.
							<p>	</p>
							<span class="image main"><img src="images/portico2.png" alt="Photo of the main campus of University College London, with the university logo in the top right corner." /></span>
							</section>
							
							<section id="registration" class="main special">
                            <header class="major">
                                    <h2>Registration and Posters</h2>
                            </header>
                            <h4><b>Registration</b></h4>
								
							<p>
							The cost is <b>¬£10</b> for non-UCL participants and <b>free</b> for UCL participants.
							<a href="https://onlinestore.ucl.ac.uk/conferences-and-events/faculty-of-mathematical-physical-sciences-c06/department-of-statistical-science-f61/f61-imss-annual-lecture-topics-on-computational-statistics-machine-learning" target="_blank" rel="noopener noreferrer">
								Link for registration
							</a>
							</p> 

                            <h4><b>Call for posters</b></h4>
							<p>
							We welcome poster presentations broadly related to computational statistics and machine learning. 
							<a href=https://forms.microsoft.com/Pages/ResponsePage.aspx?id=_oivH5ipW0yTySEKEdmlwpZA9mVzyBREiJcV5SapJ05UQzBJSFgzQ0JMVDU5MFg4RkY2T0tNM0NFRy4u>Link for poster submission</a>. 
							</p>


						</section>
						<section id="Mackey_intro" class="main special">
						<h2>Dr. Lester Mackey</h2>

						<header class="major">
						<div class="speaker-row">
							<img src="images/lester_long.png" alt="Dr. Lester Mackey" class="speaker-photo" />

							<div class="speaker-text">
							<h4>
								Lester Mackey is a Senior Principal Researcher at Microsoft Research, where he develops machine learning methods, models, and theory for large-scale learning tasks driven by applications from meteorology, healthcare, and the social good.
                Lester moved to Microsoft from Stanford University, where he was an assistant professor of Statistics and, by courtesy, of Computer Science. He earned his PhD in Computer Science and MA in Statistics from UC Berkeley and his BSE in Computer Science from Princeton University.
                He co-organized the second place team in the Netflix Prize competition for collaborative filtering; won the Prize4Life ALS disease progression prediction challenge; won prizes for temperature and precipitation forecasting in the yearlong real-time Subseasonal Climate Forecast Rodeo; and received best paper, outstanding paper, and best student paper awards from the ACM Conference on Programming Language Design and Implementation, the Conference on Neural Information Processing Systems, and the International Conference on Machine Learning.
                He is a 2023 MacArthur Fellow, a Fellow of the Institute of Mathematical Statistics, a Fellow of the American Statistical Association, an elected member of the COPSS Leadership Academy, and the recipient of the 2023 Ethel Newbold Prize and the 2025 COPSS Presidents' Award.
							</h4>
							</div>
						</div>
						</header>
						<!-- Schedule -->
							<section id="schedule" class="main special">
								<header class="major">
									<h2>Schedule</h2>
								</header>
								<h3><b>Monday, April 27th 2026</b></h3>
								<div class="table-wrapper">
									<table>
										<tbody>
											<tr>
												<td width=15%>12:00‚Äì12:40</td>
												<td align="left">üìù Registration</td>
											</tr>
											<tr>
												<td>12:40‚Äì12:45</td>
												<td align="left">üëã Welcome from the organisers</td>
											</tr>
											<tr>
												<td>12:45‚Äì13:45</td>
												<td align="left"><em>Keynote: Stein's Method, Learning, and Inference
</em>
												<br><b>Lester Mackey</b> (Microsoft Research & Stanford University)
												<br><a class="collapsible">[show abstract]</a>
													<div class="content">
														Stein‚Äôs method is a powerful tool from probability theory for bounding the distance between probability distributions. 
														In this talk, I‚Äôll describe how this tool designed to prove central limit theorems can be adapted to assess and improve the quality of practical inference procedures. 
														Along the way, I‚Äôll highlight applications to Markov chain Monte Carlo sampler selection, goodness-of-fit testing, generative modeling, de novo sampling, post-selection inference, distribution compression, bias correction, and nonconvex optimization, and I‚Äôll close with opportunities for future work.
													</div>
												</td>
											</tr>
											<tr>
												<td>13:45‚Äì14:15</td>
												<td align="left">‚òï  Coffee break
												</td>
											</tr>
											<tr>
												<td>14:15-15:00</td>
												<td align="left"><em>Title: Private estimation in stochastic block models</em>
												<br><b>Po-Ling Loh</b> (Cambridge University)
												<br><a class="collapsible">[show abstract]</a>
												<div class="content">
													We study the problem of private estimation for stochastic block models, where the observation comes in the form of an undirected graph, and the goal is to partition the nodes into unknown, underlying communities. 
													We consider a notion of differential privacy known as node differential privacy, meaning that two graphs are treated as neighbors if one can be transformed into the other by changing the edges connected to exactly one node. 
													The goal is to develop algorithms with optimal misclassification error rates, subject to a certain level of differential privacy.

													We present several algorithms based on private eigenvector extraction, private low-rank matrix estimation, and private SDP optimization. 
													A key contribution of our work is a method for converting a procedure which is differentially private and has low statistical error on degree-bounded graphs to one that is differentially private on arbitrary graph inputs, while maintaining good accuracy (with high probability) on typical inputs. 
													This is achieved by considering a certain smooth version of a map from the space of all undirected graphs to the space of bounded-degree graphs, which can be appropriately leveraged for privacy.
													 We discuss the relative advantages of the algorithms we introduce and also provide some lower-bounds for the performance of any private community estimation algorithm.

													This is joint work with Laurentiu Marchis, Ethan D'souza, and Tomas Flidr.															
												</div>
												</td>
											</tr>
											<tr>
												<td>15:00-15:45</td>
												<td align="left"><em>Title: Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs</em>
												<br><b>Paula Cordero</b> (Imperial College London)
												<br><a class="collapsible">[show abstract]</a>
													<div class="content">
													Recent advances such as self-consistency and test-time reinforcement learning (TTRL) improve the reliability of large language models (LLMs) without additional supervision, yet their underlying mechanisms and statistical guarantees remain poorly understood. We present a unified framework for certifiable inference in LLMs, showing that majority voting provides a statistical certificate of self-consistency: under mild assumptions, the aggregated answer coincides with the mode of the model‚Äôs terminal distribution with high probability. We derive finite-sample and anytime-valid concentration bounds that quantify this confidence, and introduce the Martingale Majority Certificate (MMC), a sequential stopping rule that adaptively determines when sufficient samples have been drawn. We further prove that label-free post-training methods such as TTRL implicitly sharpen the answer distribution by exponentially tilting it toward its mode, thereby reducing the number of samples required for certification. Building on this insight, we propose new post-training objectives that explicitly optimise this trade-off between sharpness and bias.  Together, these results explain and connect two central test-time scaling strategies, self-consistency and TTRL,  within a single statistical framework for label-free, certifiable reliability in reasoning LLMs. This work has been done in collaboration with Andrew Duncan.											</div>
												</td>
											</tr>
											<tr></tr>												
												<td>15:45‚Äì16:00</td>
												<td align="left">‚òï  Short break
												</td>
											</tr>
											<tr>
												<td>16:00-16:45</td>
												<td align="left"><em>Title: Geometry-aware Stein discrepancies for model evaluation and inference</em>
												<br><b>Alessandro Barp</b> (University College London)
												<br><a class="collapsible">[show abstract]</a>
													<div class="content">
													Assessing the quality of statistical models is challenging when likelihoods are unnormalised or when data lie on non-Euclidean spaces, as classical distances between distributions often become computationally intractable.
													In this talk, we show how Stein discrepancies exploit the curvature of the target distribution to provide a computable alternative. 
													We discuss recent results demonstrating that suitably constructed kernel Stein discrepancies can characterise Wasserstein convergence. 
													We then connect these ideas to inference on spherical data, where these discrepancies enable robust inference without requiring normalising constants.
									
													</div>
												</td>
											</tr>
											<tr>
												<td>17:00-</td>
												<td align="left"><em>üìÑ Poster Session & Reception </em>
												</td>
											</tr>
										</tbody>
									</table>
								</div>
								<br>


							</section>

						<!-- Speakers -->
							<section id="speakers" class="main special">
								<header class="major">
									<h2>Speakers</h2>
								</header>
								<ul class="features">
									<li>
										<img class="icon major" src="images/barp_2.png" alt="Photo of Alessandro Barp" width="250"/>
										<h3><a href="https://alebarp.github.io/">Alessandro Barp</a></h3>
										<p>University College London</p>
									</li>									
									<li>
										<img class="icon major" src="images/Paula.png" alt="Photo of Paula Cordero" width="250"/>
										<h3><a href="https://scholar.google.com/citations?user=R27puNcAAAAJ&hl=es">Paula Cordero</a></h3>
										<p>Imperial College London</p>
									</li>	
								</ul>
								<ul class="features">								
									<li>
										<img class="icon major" src="images/poling.jpg" alt="Photo of Po-Ling Loh" width="250"/>
										<h3><a href="https://www.dpmms.cam.ac.uk/~pll28/">Po-Ling Loh</a></h3>
										<p>University of Cambridge</p>
									</li>
									<li>
										<img class="icon major" src="images/lester_2.png" alt="Photo of Lester Mackey" width="250"/>
										<h3><a href="https://lmackey.github.io/">Lester Mackey</a></h3>
										<p>Microsoft Research & Stanford University</p>
									</li>
								</ul>
							</section>

						<!-- Schedule -->
							<section id="organisers" class="main special">
								<header class="major">
									<h2>Organisers</h2>
								</header>
								<ul class="features">
									<li>
										<img class="icon major" src="images/harita_2.png" alt="Photo of Harita Dellaporta" width="250"/>
										<h3><a href="https://haritadell.github.io/">Harita Dellaporta</a></h3>
										Lead Organiser
									</li>
									<li>
										<img class="icon major" src="images/fx.png" alt="Photo of Fran√ßois-Xavier Briol" width="250"/>
										<h3><a href="https://fxbriol.github.io/">Fran√ßois-Xavier Briol</a></h3>
										Co-organiser
									</li>
								</ul>
									<ul class="features">
									<li>
										<img class="icon major" src="images/hudson_2.png" alt="Photo of Hudson Chen" width="250"/>
										<h3><a href="https://hudsonchen.github.io/">Zonghao (Hudson) Chen</a></h3>
										Co-organiser
									</li>
									<li>
										<img class="icon major" src="images/william_2.png" alt="Photo of William Laplante" width="250"/>
										<h3><a href="https://williamlaplante.github.io/">William Laplante</a></h3>
										Co-organiser
									</li>
								</ul>
								<!--<p>We are very grateful for funding from the <a href="https://www.grad.ucl.ac.uk/funds/ucl-fellowship-incubator-awards.html">UCL Fellowship Incubator Fund</a>, the <a href="https://www.ucl.ac.uk/statistics/department-statistical-science">UCL Department of Statistical Science</a>, the <a href="https://www.ucl.ac.uk/mathematical-statistical-sciences/institute-mathematical-and-statistical-sciences">UCL Institute for Mathematical and Statistical Sciences (IMSS)</a>, and <a href="https://www.ucl.ac.uk/foundational-ai-cdt/foundational-artificial-intelligence-mphilphd">UKRI CDT in Foundational AI</a> funded by the Engineering and Physical Sciences Research Council [EP/S021566/1].</p>-->
							</section>
						<!-- Location -->
							<section id="location" class="main special">
								<header class="major">
									<h2>Location</h2>
								</header>
								<p>Location: Gustave Tuck Lecture Theatre, Gower St, London WC1E 6BT, UK</p>
								<a href="https://maps.app.goo.gl/BmWw2cVmqgJFZvaS8">Google Maps</a> </p>
							</section>
							    <img src="images/theatre_2.png"
									alt="Gustave Tuck Lecture Theatre"
									class="location-image">
				</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; DBMML workshop. Design by <a href="https://html5up.net">HTML5UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
